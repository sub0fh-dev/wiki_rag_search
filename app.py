import os
import pandas as pd
import streamlit as st
from openai import OpenAI
from elasticsearch import Elasticsearch

# ===============================
# OpenAI & Elasticsearch ì„¤ì •
# ===============================
client = OpenAI(api_key=st.secrets["api_key"])

ELASTIC_CLOUD_ID = st.secrets["elastic_cloud_key"]
ELASTIC_API_KEY = st.secrets["elastic_api_key"]

es = Elasticsearch(
    cloud_id=ELASTIC_CLOUD_ID,
    api_key=ELASTIC_API_KEY
)

# ì—°ê²° í…ŒìŠ¤íŠ¸
try:
    es_info = es.info()
    print("Elasticsearch ì—°ê²° ì„±ê³µ!")
except Exception as e:
    st.error("Elasticsearch ì—°ê²° ì‹¤íŒ¨: " + str(e))

# ===============================
# Streamlit UI
# ===============================
st.set_page_config(page_title="Kevin AI Wiki", layout="wide")

st.markdown("<h1 style='text-align:center; color: #4B0082;'>í•œê¸€ë¡œ ë‹µë³€í•˜ëŠ” AI</h1>", unsafe_allow_html=True)
st.markdown("<h3 style='text-align:center; color: #6A5ACD;'>ì˜ë¬¸ ìœ„í‚¤ ê¸°ë°˜ RAG (Retrieval Augmented Generation)</h3>", unsafe_allow_html=True)
st.markdown("---")

st.markdown("""
ì˜ë¬¸ Wikipedia ë°ì´í„°ë¥¼ í™œìš©í•˜ì—¬ ì§ˆë¬¸ì— í•œêµ­ì–´ë¡œ ë‹µë³€í•©ë‹ˆë‹¤.  
ì˜ˆì‹œ ì§ˆë¬¸: 
- ëŒ€ì„œì–‘ì€ ëª‡ ë²ˆì§¸ë¡œ í° ë°”ë‹¤ì¸ê°€?
- ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ”?
- ì´ìˆœì‹ ì˜ ì¶œìƒë…„ë„ëŠ”?
- ë„ìš”íƒ€ì—ì„œ ê°€ì¥ ë§ì´ íŒ”ë¦¬ëŠ” ì°¨ëŠ”?
""")

st.markdown("""
ë°ì´í„° ì¶œì²˜:  
[Wiki Embeddings ìƒ˜í”Œ ë°ì´í„°](https://cdn.openai.com/API/examples/data/vector_database_wikipedia_articles_embedded.zip)  
ë°ì´í„° ì„¤ëª…: [Weaviate Tutorial](https://weaviate.io/developers/weaviate/tutorials/wikipedia)  
ë°ì´í„° ê±´ìˆ˜: 25,000ê±´
""")

st.markdown("---")

# ===============================
# ì§ˆë¬¸ ì…ë ¥ í¼
# ===============================
with st.form("question_form"):
    question = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”")
    submit = st.form_submit_button("ì§ˆë¬¸í•˜ê¸°")

if submit and question:
    with st.spinner("Kevin AIê°€ ë‹µë³€ ì¤€ë¹„ ì¤‘..."):
        # 1ï¸âƒ£ í•œêµ­ì–´ â†’ ì˜ì–´ ë²ˆì—­
        translated = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {
                    "role": "user",
                    "content": "Translate the following Korean question into English: " + question
                }
            ]
        )
        english_question = translated.choices[0].message.content
        print("ë²ˆì—­:", english_question)

        # 2ï¸âƒ£ ì§ˆë¬¸ ì„ë² ë”© ìƒì„±
        question_embedding = client.embeddings.create(
            input=[english_question],
            model="text-embedding-ada-002"
        ).data[0].embedding

        # 3ï¸âƒ£ Elasticsearch ê²€ìƒ‰
        try:
            response = es.search(
                index="wikipedia_vector_index",
                knn={
                    "field": "content_vector",
                    "query_vector": question_embedding,
                    "k": 10,
                    "num_candidates": 100
                }
            )
        except Exception as e:
            st.error("Elasticsearch ê²€ìƒ‰ ì‹¤íŒ¨: " + str(e))
            st.stop()

        # 4ï¸âƒ£ ìµœìƒìœ„ ë¬¸ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        top_hit_summary = response['hits']['hits'][0]['_source']['text']

        # 5ï¸âƒ£ GPTë¡œ í•œêµ­ì–´ ìš”ì•½/ë‹µë³€ ìƒì„±
        summary = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {
                    "role": "system",
                    "content": "You are an assistant for question-answering tasks. Use the retrieved context to answer concisely in Korean. If unknown, say 'ì œê°€ ê°€ì§„ ì •ë³´ë¡œëŠ” ì•Œ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'"
                },
                {
                    "role": "user",
                    "content": f"Question: {english_question} Context: {top_hit_summary} Answer in Korean in maximum 3 sentences."
                }
            ]
        )

        # 6ï¸âƒ£ ë‹µë³€ ì¶œë ¥
        st.markdown("### ğŸ’¡ Kevin AI ë‹µë³€")
        st.info(summary.choices[0].message.content)

        # 7ï¸âƒ£ ê²€ìƒ‰ëœ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
        st.markdown("### ğŸ” ê´€ë ¨ Wiki ë¬¸ì„œ")
        for hit in response['hits']['hits']:
            title = hit['_source']['title']
            url = hit['_source']['url']
            score = hit['_score']
            st.markdown(f"- [{title}]({url}) (Score: {score:.2f})")
